{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here I have developed the AI-powered Content Creator Agent using the Llama 3.1 405B model, known for generating highly coherent and relevant text. This model is accelerated by NVIDIA LLM NIM microservices, ensuring exceptional computational efficiency and scalability.\n",
        "\n",
        "Key to this project is the integration of LangChain’s ChatNVIDIA—an open-source Python library contributed by NVIDIA,which facilitates seamless interaction with NVIDIA NIM. Through LangChain runnable chain expressions (LCEL), we consolidated these capabilities into a streamlined, reliable, and structured workflow.\n",
        "\n",
        "The Content Creator Agent not only simplifies the process but also delivers personalized, high-quality social media content tailored to user needs. By leveraging cutting-edge AI technologies, this project revolutionizes content creation, making it scalable and accessible for a wide range of users."
      ],
      "metadata": {
        "id": "1BzVFIBhL3N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-nvidia-ai-endpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFN7KQXjk3Tc",
        "outputId": "ffc135f3-0d9e-4a95-b57b-682c3210fbe9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-nvidia-ai-endpoints in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (3.11.10)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (0.3.25)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.18.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.27.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (3.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-nvidia-ai-endpoints) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
        "## 10K free queries to any endpoint (which is a lot actually).\n",
        "\n",
        "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
        "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
        "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
        "else:\n",
        "    global nvapi_key\n",
        "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
        "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J-V_Xr3vZbm",
        "outputId": "1e913c97-c29e-44c9-c5de-a68d5124e0ae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVAPI Key (starts with nvapi-): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Content Creator Agent\n",
        "This section demonstrates the construction of a Content Creator Agent for generating promotional messages tailored to specific guidelines. The agent utilizes the following technologies and workflows:\n",
        "\n",
        "NVIDIA API Endpoints: Employing the NVIDIA API catalog preview endpoints for message generation. For NVIDIA AI Enterprise customers, these endpoints can also be run locally via NIM.\n",
        "LangChain Integration: The agent leverages LangChain\\u2019s ChatNVIDIA to interact seamlessly with NVIDIA's advanced AI models and ensure structured output.\n",
        "Template Design: A predefined system prompt guides the AI in generating promotional content based on the provided product description. The output adheres to a specific format that includes a title, message, and relevant hashtags.\n",
        "Structured Output: Using LangChain\\u2019s StructuredOutput capabilities, the agent organizes responses into fields such as Title, Message, and Tags, ensuring reliable and formatted results."
      ],
      "metadata": {
        "id": "WaE2QuHKMjM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test run and see that you can genreate a respond successfully\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain import prompts, chat_models, hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
        "from typing import Optional, List\n",
        "\n",
        "## construct the system prompt\n",
        "prompt_template = \"\"\"\n",
        "### [INST]\n",
        "\n",
        "You are an expert social media content creator.\n",
        "Your task is to create a different promotion message with the following\n",
        "Product Description :\n",
        "------\n",
        "Achieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\n",
        "------\n",
        "\n",
        "The output promotion message MUST use the following format :\n",
        "\n",
        "'''\n",
        "Title: a powerful, short message that dipict what this product is about\n",
        "Message: be creative for the promotion message, but make it short and ready for social media feeds.\n",
        "Tags: the hash tag human will nomally use in social media\n",
        "'''\n",
        "\n",
        "Begin!\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "input_variables=['produce_desc'],\n",
        "template=prompt_template,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "## provide the product_desc\n",
        "product_desc=\"Achieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\"\n",
        "\n",
        "## structural output using LMFE\n",
        "class StructureOutput(BaseModel):\n",
        "    Title: str = Field(description=\"Title of the promotion message\")\n",
        "    Message : str = Field(description=\"The actual promption message\")\n",
        "    Tags: List[str] = Field(description=\"Hash tags for social media, usually starts with #\")\n",
        "\n",
        "llm_with_output_structure=ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\").with_structured_output(StructureOutput)\n",
        "\n",
        "## construct the content_creator agent\n",
        "content_creator = ( prompt | llm_with_output_structure )\n",
        "out=content_creator.invoke({\"product_desc\":product_desc})"
      ],
      "metadata": {
        "id": "BcvMLgG1xNU3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKwlB0gr7UTe",
        "outputId": "9d12bafe-92df-4e84-b819-69df4d804890"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructureOutput(Title='UNLEASH YOUR FITNESS GOALS!', Message='Get ready to upgrade your home gym with our versatile multi-purpose gym bench! With adjustable settings, anti-slip padding, and a compact foldable design, you can take your strength training, cardio, and flexibility workouts to the NEXT LEVEL! Perfect for beginners and fitness enthusiasts alike!', Tags=['#FitnessMotivation', '#HomeGymEssentials', '#GymBenchGoals', '#WorkoutInspiration', '#FitnessEnthusiast'])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.Title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gWqYn2t17AGT",
        "outputId": "f1cc4804-4fff-485f-9d28-1febf9a0b65d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UNLEASH YOUR FITNESS GOALS!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.Message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qaGYbCNe7YIw",
        "outputId": "4a2884b7-1d9a-42d9-cdfc-c94d4cbeafa6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Get ready to upgrade your home gym with our versatile multi-purpose gym bench! With adjustable settings, anti-slip padding, and a compact foldable design, you can take your strength training, cardio, and flexibility workouts to the NEXT LEVEL! Perfect for beginners and fitness enthusiasts alike!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.Tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQRCrs-Z7hLn",
        "outputId": "cc7fe771-a372-4707-dcd5-5f1ed2ed8797"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FitnessMotivation',\n",
              " '#HomeGymEssentials',\n",
              " '#GymBenchGoals',\n",
              " '#WorkoutInspiration',\n",
              " '#FitnessEnthusiast']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Digital Artist Agent:\n",
        "This section showcases the Digital Artist Agent, designed to transform promotional text into visually engaging content for social media campaigns. The agent integrates cutting-edge technologies to produce high-quality visuals based on user-provided prompts:\n",
        "\n",
        "*  Text-to-Image Model: Utilizes NVIDIA's sdXL-turbo text-to-image model for generating creative visuals tailored to promotional needs.\n",
        "*  Prompt Optimization: Automatically rewrites input promotional text into image generation prompts using a language model, ensuring alignment with visual design requirements.\n",
        "*  High-Quality Output: Generates visually appealing images ideal for social media campaigns, enhancing the promotional impact of your content.\n",
        "\n",
        "Key Workflow:\n",
        "1. Rewrite Input: The agent refines the provided promotional title or description into a prompt optimized for image generation.\n",
        "2. Image Generation: Communicates with the NVIDIA sdXL-turbo API to generate and save the image locally.\n",
        "3. Output Location: The generated image is saved as output.jpg for easy retrieval and use\n"
      ],
      "metadata": {
        "id": "XhdccdhzNt6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64, io\n",
        "from PIL import Image\n",
        "import requests, json\n",
        "def generate_image(prompt :str) -> str :\n",
        "    \"\"\"\n",
        "    generate image from text\n",
        "    Args:\n",
        "        prompt: input text\n",
        "    \"\"\"\n",
        "    ## re-writing the input promotion title in to appropriate image_gen prompt\n",
        "    gen_prompt=llm_rewrite_to_image_prompts(prompt)\n",
        "    print(\"start generating image with llm re-write prompt:\", gen_prompt)\n",
        "    invoke_url = \"https://ai.api.nvidia.com/v1/genai/stabilityai/sdxl-turbo\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {nvapi_key}\",\n",
        "        \"Accept\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"text_prompts\": [{\"text\": gen_prompt}],\n",
        "        \"seed\": 0,\n",
        "        \"sampler\": \"K_EULER_ANCESTRAL\",\n",
        "        \"steps\": 2\n",
        "    }\n",
        "\n",
        "    response = requests.post(invoke_url, headers=headers, json=payload)\n",
        "\n",
        "    response.raise_for_status()\n",
        "    response_body = response.json()\n",
        "    ## load back to numpy array\n",
        "    print(response_body['artifacts'][0].keys())\n",
        "    imgdata = base64.b64decode(response_body[\"artifacts\"][0][\"base64\"])\n",
        "    filename = 'output.jpg'\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(imgdata)\n",
        "    im = Image.open(filename)\n",
        "    img_location=f\"the output of the generated image will be stored in this path : {filename}\"\n",
        "    return img_location"
      ],
      "metadata": {
        "id": "nCxGUqfu7jhW"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section introduces a Python script that refines user queries into concise, image-generation prompts optimized for creative output. The rewriter ensures that the transformed prompt aligns with specific stylistic and structural requirements for text-to-image models."
      ],
      "metadata": {
        "id": "-tPBgVOXOdOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test run and see that you can genreate a respond successfully\n",
        "\n",
        "def llm_rewrite_to_image_prompts(user_query):\n",
        "    prompt = prompts.ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Summarize the following user query into a very short, one-sentence theme for image generation, MUST follow this format : A iconic, futuristic image of , no text, no amputation, no face, bright, vibrant\",\n",
        "            ),\n",
        "            (\"user\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    model = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
        "    chain = ( prompt    | model   | StrOutputParser() )\n",
        "    out= chain.invoke({\"input\":user_query})\n",
        "    #print(type(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "QcQsbBn77i6U"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=generate_image(\"UNLEASH YOUR FITNESS GOALS!\")\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "aVlHevCF7jjk",
        "outputId": "0c5304b2-19d7-4ca3-9951-12f911ab8f39"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start generating image with llm re-write prompt: A iconic, futuristic image of a vibrant and bright fitness center with advanced equipment, no text, no amputation, no face.\n",
            "dict_keys(['base64', 'finishReason', 'seed'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the output of the generated image will be stored in this path : output.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
        "llm_with_img_gen_tool=llm.bind_tools([generate_image],tool_choice=\"generate_image\")"
      ],
      "metadata": {
        "id": "raOmsa5v7jl6"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=llm_with_img_gen_tool.invoke(\"Unlock Your Fitness Potential\")\n",
        "out.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pw4Jijt7joM",
        "outputId": "80b2fdd0-0acf-4f35-8c3f-141c182af7c9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'generate_image',\n",
              "  'args': {'prompt': 'Unlock Your Fitness Potential'},\n",
              "  'id': 'chatcmpl-tool-20f6ceb54e4f4a1fb0c702fa3fa48967',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def output_to_invoke_tools(out):\n",
        "    tool_calls=out.tool_calls\n",
        "    ## check there are indeed tool_calls in the output\n",
        "    if len(tool_calls) > 0 :\n",
        "        ## assert the args attribute exists\n",
        "        if 'args' in tool_calls[0] :\n",
        "\n",
        "            prompt=tool_calls[0]['args']['prompt']\n",
        "            output=generate_image(prompt)\n",
        "        else:\n",
        "            print(\"### out.tool_calls\", out.tool_calls[0].keys() )\n",
        "            output=\"cannot find input prompt from llm output, please rerun again\"\n",
        "    else:\n",
        "        print(\"------------\" , out)\n",
        "        print(\"### out.tool_calls\", out.tool_calls )\n",
        "        output=\"agent did not find generate_image tool, please check the tool binding is successful\"\n",
        "    return output"
      ],
      "metadata": {
        "id": "mCoqQXJj7jqY"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digital_artist = (\n",
        "    llm_with_img_gen_tool\n",
        "    | output_to_invoke_tools\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "s3TWLRua7jsn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digital_artist.invoke(\"Hit Gym get fit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "lrBPZY1O7ju1",
        "outputId": "61f5bc87-e2b0-4827-d4fd-6f354e998854"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start generating image with llm re-write prompt: A iconic, futuristic image of a man lifting weights and getting fit in a bright, vibrant gym setting, without text, face, or amputation.\n",
            "dict_keys(['base64', 'finishReason', 'seed'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the output of the generated image will be stored in this path : output.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community\n",
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTVUgd4B8m95",
        "outputId": "5a8eace4-1fca-47e8-936e-5dcd93d842b1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.60-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.28)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.48-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
            "Downloading langgraph-0.2.60-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
            "Downloading langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "Successfully installed langgraph-0.2.60 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Integrating Human-in-the-Loop: Decision-Maker Role\n",
        "To ensure oversight and maintain high-quality outputs, human decision-makers are integrated into the workflow. This process allows for review, refinement, and final approval of the results generated by the agents, promoting collaboration between AI and human expertise.\n",
        "\n",
        "Key Features:\n",
        "*  Human-Centered Oversight: Places humans at the center of decision-making, allowing for review and iteration of both text and image outputs to meet deployment standards.\n",
        "*  Agent Selection: Human decision-makers evaluate the task requirements and choose the appropriate agent—either the Content Creator Agent or the Digital Artist Agent—for each task.\n",
        "*  Multiple Iterations: Enables refinement of outputs through human review, ensuring promotional messages and visuals are polished and aligned with expectations.\n",
        "Agentic Cognitive Architecture: Utilizes LangGraph to orchestrate agent workflows, ensuring seamless communication and task assignment.\n"
      ],
      "metadata": {
        "id": "LEcciAGMPBWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Or you can directly instantiate the tool\n",
        "from langchain_community.tools import HumanInputRun\n",
        "from langchain.agents import AgentType, load_tools\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "\n",
        "def get_human_input() -> str:\n",
        "    \"\"\" Put human as decision maker, human will decide which agent is best for the task\"\"\"\n",
        "\n",
        "    print(\"You have been given 2 agents. Please select exactly _ONE_ agent to help you with the task, enter 'y' to confirm your choice.\")\n",
        "    print(\"\"\"Available agents are : \\n\n",
        "            1 ContentCreator  \\n\n",
        "            2 DigitalArtist \\n\n",
        "            Enter 1 or 2\"\"\")\n",
        "    contents = []\n",
        "    while True:\n",
        "        try:\n",
        "            line = input()\n",
        "            if line=='1':\n",
        "                tool=\"ContentCreator\"\n",
        "                line=tool\n",
        "\n",
        "            elif line=='2':\n",
        "                tool=\"DigitalArtist\"\n",
        "                line=tool\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        except EOFError:\n",
        "            break\n",
        "        if line == \"y\":\n",
        "            print(f\"tool selected : {tool} \")\n",
        "            break\n",
        "        contents.append(line)\n",
        "\n",
        "    return \"\\n\".join(contents)\n",
        "\n",
        "\n",
        "# You can modify the tool when loading\n",
        "\n",
        "ask_human = HumanInputRun(input_func=get_human_input)"
      ],
      "metadata": {
        "id": "taYqlaLp7jxF"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## first we define GraphState\n",
        "from typing import Dict, TypedDict\n",
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "class State(TypedDict):\n",
        "    # The input string\n",
        "    input: str\n",
        "    input_to_agent : str\n",
        "    agent_choice : str\n",
        "    agent_use_tool_respond : str"
      ],
      "metadata": {
        "id": "-MituRk_7j0n"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "527jDAdY9pTv",
        "outputId": "f8126e2e-d790-46d5-ea11-716306534b31"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section demonstrates how i used LangGraph to create nodes that represent steps or actions in an agent-driven workflow. These nodes enable sequential or parallel execution of tasks, providing a structured and flexible approach to managing complex processes."
      ],
      "metadata": {
        "id": "Lh4nCflFP6zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.prebuilt import ToolInvocation\n",
        "from colorama  import Fore,Style\n",
        "# Define the functions needed\n",
        "def human_assign_to_agent(state):\n",
        "    # ensure using original prompt\n",
        "    inputs = state[\"input\"]\n",
        "    input_to_agent = state[\"input_to_agent\"]\n",
        "\n",
        "    concatenate_str = Fore.BLUE+inputs+ ' : '+Fore.CYAN+input_to_agent + Fore.RESET\n",
        "    print(concatenate_str)\n",
        "    print(\"---\"*10)\n",
        "\n",
        "    agent_choice=ask_human.invoke(concatenate_str)\n",
        "    print(Fore.CYAN+ \"choosen_agent : \" + agent_choice + Fore.RESET)\n",
        "    return {\"agent_choice\": agent_choice }\n",
        "\n",
        "def agent_execute_task(state):\n",
        "    inputs= state[\"input\"]\n",
        "    input_to_agent = state[\"input_to_agent\"]\n",
        "    print(Fore.CYAN+input_to_agent + Fore.RESET)\n",
        "    # choosen agent will execute the task\n",
        "    choosen_agent = state['agent_choice']\n",
        "    if choosen_agent=='ContentCreator':\n",
        "        structured_respond=content_creator.invoke({\"product_desc\":input_to_agent})\n",
        "        respond='\\n'.join([structured_respond.Title,structured_respond.Message,''.join(structured_respond.Tags)])\n",
        "    elif choosen_agent==\"DigitalArtist\":\n",
        "        respond=digital_artist.invoke(input_to_agent)\n",
        "    else:\n",
        "        respond=\"please reselect the agent, there are only 2 agents available: 1.ContentCreator or 2.DigitalArtist\"\n",
        "\n",
        "\n",
        "    print(Fore.CYAN+ \"agent_output: \\n\" + respond + Fore.RESET)\n",
        "\n",
        "    return {\"agent_use_tool_respond\": respond}"
      ],
      "metadata": {
        "id": "D9Qrwofz9L8r"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Define the two nodes\n",
        "workflow.add_node(\"start\", human_assign_to_agent)\n",
        "workflow.add_node(\"end\", agent_execute_task)\n",
        "\n",
        "# This means that this node is the first one called\n",
        "workflow.set_entry_point(\"start\")\n",
        "workflow.add_edge(\"start\", \"end\")\n",
        "workflow.add_edge(\"end\", END)\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "QBLqBBkw9L_O"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_query=\"create a good promption message for social promotion events using the following inputs\"\n",
        "product_desc=\"Achieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\"\n",
        "respond=app.invoke({\"input\":my_query, \"input_to_agent\":product_desc})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akYOhbiI9MBg",
        "outputId": "b110ab52-6872-4b87-d594-14aa9e6dee66"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mcreate a good promption message for social promotion events using the following inputs : \u001b[36mAchieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\u001b[39m\n",
            "------------------------------\n",
            "\n",
            "\n",
            "\u001b[34mcreate a good promption message for social promotion events using the following inputs : \u001b[36mAchieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\u001b[39m\n",
            "You have been given 2 agents. Please select exactly _ONE_ agent to help you with the task, enter 'y' to confirm your choice.\n",
            "Available agents are : \n",
            "\n",
            "            1 ContentCreator  \n",
            "\n",
            "            2 DigitalArtist \n",
            "          \n",
            "            Enter 1 or 2\n",
            "1\n",
            "y\n",
            "tool selected : ContentCreator \n",
            "\u001b[36mchoosen_agent : ContentCreator\u001b[39m\n",
            "\u001b[36mAchieve your fitness goals with our versatile and durable multi-purpose gym bench. Designed for strength training, cardio, and flexibility workouts, it features adjustable settings for various exercises, anti-slip padding for safety, and a compact foldable design for easy storage. Perfect for beginners and fitness enthusiasts alike\u001b[39m\n",
            "\u001b[36magent_output: \n",
            "UNLEASH YOUR FITNESS POTENTIAL\n",
            "Get fit, stay fit with our ultimate multi-purpose gym bench. Train with confidence, store with ease. Limited offer: Get yours now and start crushing your fitness goals!\n",
            "#fitnessmotivation #gymessentials #fitnessgoals #multipurposegymbench #workoutfromhome #fitnessjourney\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_for_image=respond['agent_use_tool_respond'].split('\\n')[0].split(':')[-1].strip()\n",
        "prompt_for_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NjNl1wOO9MD3",
        "outputId": "427b8eed-8c89-4dd6-9ccc-e82f63287cb7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UNLEASH YOUR FITNESS POTENTIAL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_query=\"generate an image for me from the below promotion message\"\n",
        "respond2=app.invoke({\"input\":input_query, \"input_to_agent\":prompt_for_image})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8lRGKzV9MGR",
        "outputId": "883c6bfb-b57b-4876-b9cd-43399261dd44"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mgenerate an image for me from the below promotion message : \u001b[36mUNLEASH YOUR FITNESS POTENTIAL\u001b[39m\n",
            "------------------------------\n",
            "\n",
            "\n",
            "\u001b[34mgenerate an image for me from the below promotion message : \u001b[36mUNLEASH YOUR FITNESS POTENTIAL\u001b[39m\n",
            "You have been given 2 agents. Please select exactly _ONE_ agent to help you with the task, enter 'y' to confirm your choice.\n",
            "Available agents are : \n",
            "\n",
            "            1 ContentCreator  \n",
            "\n",
            "            2 DigitalArtist \n",
            "          \n",
            "            Enter 1 or 2\n",
            "2\n",
            "y\n",
            "tool selected : DigitalArtist \n",
            "\u001b[36mchoosen_agent : DigitalArtist\u001b[39m\n",
            "\u001b[36mUNLEASH YOUR FITNESS POTENTIAL\u001b[39m\n",
            "start generating image with llm re-write prompt: \"A iconic, futuristic image of a vibrant, bright gym showcasing advanced fitness technology, with no text, faces, or amputations.\"\n",
            "dict_keys(['base64', 'finishReason', 'seed'])\n",
            "\u001b[36magent_output: \n",
            "the output of the generated image will be stored in this path : output.jpg\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.open('output.jpg')\n",
        "im.show()"
      ],
      "metadata": {
        "id": "eZwHZOe99MIo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = respond['agent_use_tool_respond'].split('\\n')[0].split(':')[-1].strip() if '\\n' in respond['agent_use_tool_respond'] else respond['agent_use_tool_respond'].split(':')[-1].strip()\n",
        "try:\n",
        "    promotion_msg = respond['agent_use_tool_respond'].split('\\n')[1].split(':')[-1].strip()\n",
        "except IndexError:\n",
        "    promotion_msg = \"No promotion message available.\"  # Or any other default value\n",
        "hash_tags = ['#' + s for s in respond['agent_use_tool_respond'].split('\\n')[-1].split(':')[-1].split('#') if s != \"\"]\n"
      ],
      "metadata": {
        "id": "34ZLzJHb9MLD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hash_tag_in_md=[]\n",
        "for hash_tag in hash_tags:\n",
        "\n",
        "    temp=f\"\"\"<span>{hash_tag}</span>\"\"\"\n",
        "    hash_tag_in_md.append(temp)\n",
        "\n",
        "hashtags_in_md= '<br>'+ ''.join(hash_tag_in_md) + '</br>'"
      ],
      "metadata": {
        "id": "phFCejm99MNL"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "import markdown\n",
        "markdown_str = markdown.markdown(f'''\n",
        "<img src=\"output.jpg\" width=600 height=480 class=center/>\n",
        "\n",
        "\n",
        "#### {title}\n",
        "\n",
        "{promotion_msg}\n",
        "\n",
        "{hashtags_in_md}\n",
        "\n",
        "''')\n",
        "\n",
        "def printmd(markdown_str):\n",
        "    display(Markdown(markdown_str))\n",
        "printmd(markdown_str)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/output.jpg": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "sjKsWdm39MPo",
        "outputId": "8e8db4f2-74b7-4218-8fbd-dd45ee7e48f6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<p><img src=\"output.jpg\" width=600 height=480 class=center/></p>\n<h4>output.jpg</h4>\n<p>No promotion message available.</p>\n<p><br><span># output.jpg</span></br></p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvpAr5oo9MR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDs-uBwx9MUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fexMYUiH9MXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ktm72egD9MZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsyyG4ON9Mbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H19V9vXh9MeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJfOFzWu9Mgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNNgbG899Miq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nz1iUPfe9MlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rb5agEgl9MnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPboqVZe9Mp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test run and see that you can genreate a respond successfully\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain import prompts, chat_models, hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "def llm_rewrite_to_image_prompts(user_query):\n",
        "    prompt = prompts.ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Summarize the following user query into a very short, one-sentence theme for image generation, MUST follow this format : A iconic, futuristic image of , no text, no amputation, no face, bright, vibrant\",\n",
        "            ),\n",
        "            (\"user\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    model = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
        "    chain = ( prompt    | model   | StrOutputParser() )\n",
        "    out= chain.invoke({\"input\":user_query})\n",
        "    #print(type(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "0IKLlsox6CNk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64, io\n",
        "from PIL import Image\n",
        "import requests, json\n",
        "def generate_image(prompt :str) -> str :\n",
        "    \"\"\"\n",
        "    generate image from text\n",
        "    Args:\n",
        "        prompt: input text\n",
        "    \"\"\"\n",
        "    ## re-writing the input promotion title in to appropriate image_gen prompt\n",
        "    gen_prompt=llm_rewrite_to_image_prompts(prompt)\n",
        "    print(\"start generating image with llm re-write prompt:\", gen_prompt)\n",
        "    invoke_url = \"https://ai.api.nvidia.com/v1/genai/stabilityai/sdxl-turbo\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {a}\",\n",
        "        \"Accept\": \"application/json\",\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"text_prompts\": [{\"text\": gen_prompt}],\n",
        "        \"seed\": 0,\n",
        "        \"sampler\": \"K_EULER_ANCESTRAL\",\n",
        "        \"steps\": 2\n",
        "    }\n",
        "\n",
        "    response = requests.post(invoke_url, headers=headers, json=payload)\n",
        "\n",
        "    response.raise_for_status()\n",
        "    response_body = response.json()\n",
        "    ## load back to numpy array\n",
        "    print(response_body['artifacts'][0].keys())\n",
        "    imgdata = base64.b64decode(response_body[\"artifacts\"][0][\"base64\"])\n",
        "    filename = 'output.jpg'\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(imgdata)\n",
        "    im = Image.open(filename)\n",
        "    img_location=f\"the output of the generated image will be stored in this path : {filename}\"\n",
        "    return img_location"
      ],
      "metadata": {
        "id": "YAYAGucV4UxT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out=generate_image(\"NVIDIA NeMo is a powerful SDK for all your GenAI needs\")\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "c4PCtaGn5OJ1",
        "outputId": "9b3cb14b-e0c3-4a94-c22c-341354e621da"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py:176: UserWarning: An API key is required for the hosted NIM. This will become an error in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "[401] Unauthorized\nAuthentication failed\nPlease check or regenerate your API key.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-8d1f9bf9345f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NVIDIA NeMo is a powerful SDK for all your GenAI needs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-12f9c332319a>\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m## re-writing the input promotion title in to appropriate image_gen prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgen_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_rewrite_to_image_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start generating image with llm re-write prompt:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minvoke_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://ai.api.nvidia.com/v1/genai/stabilityai/sdxl-turbo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-300461a46c9e>\u001b[0m in \u001b[0;36mllm_rewrite_to_image_prompts\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatNVIDIA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mistralai/mixtral-8x7b-instruct-v0.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mprompt\u001b[0m    \u001b[0;34m|\u001b[0m \u001b[0mmodel\u001b[0m   \u001b[0;34m|\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(type(out))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_for_vlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_req\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_callback_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36mget_req\u001b[0;34m(self, payload, extra_headers)\u001b[0m\n\u001b[1;32m    471\u001b[0m     ) -> Response:\n\u001b[1;32m    472\u001b[0m         \u001b[0;34m\"\"\"Post to the API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         response, session = self._post(\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, invoke_url, payload, extra_headers)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add_authorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         )\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36m_try_raise\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\nPlease check or regenerate your API key.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# todo: raise as an HTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{header}\\n{body}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;31m###################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: [401] Unauthorized\nAuthentication failed\nPlease check or regenerate your API key."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain import prompts, chat_models, hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "\n",
        "def llm_rewrite_to_image_prompts(user_query):\n",
        "    prompt = prompts.ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Summarize the following user query into a very short, one-sentence theme for image generation, MUST follow this format : A iconic, futuristic image of , no text, no amputation, no face, bright, vibrant\",\n",
        "            ),\n",
        "            (\"user\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    model = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
        "    chain = ( prompt    | model   | StrOutputParser() )\n",
        "    out= chain.invoke({\"input\":user_query})\n",
        "    #print(type(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "k240IAkz4e17"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## bind image generation as tool into llama3.1-405b llm\n",
        "llm=ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
        "llm_with_img_gen_tool=llm.bind_tools([generate_image],tool_choice=\"generate_image\")\n",
        "## use LCEL to construct Digital Artist Agent\n",
        "digital_artist = (\n",
        "    llm_with_img_gen_tool\n",
        "    | output_to_invoke_tools\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "YZgovUeh4ng6",
        "outputId": "5950844e-8916-4131-ceff-04c8a5f8dbfb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py:176: UserWarning: An API key is required for the hosted NIM. This will become an error in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'output_to_invoke_tools' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-228a64d1ab2b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m digital_artist = (\n\u001b[1;32m      6\u001b[0m     \u001b[0mllm_with_img_gen_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m|\u001b[0m \u001b[0moutput_to_invoke_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_to_invoke_tools' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNSuB_QM4xQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}